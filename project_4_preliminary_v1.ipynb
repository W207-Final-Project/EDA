{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 4: Final Project - Random Acts of Pizza\n",
    "### Predicting altruism through free pizza\n",
    "\n",
    "This project is originated from the Kaggle competition https://www.kaggle.com/c/random-acts-of-pizza. We will create an algorithm to predict which requests will recieve pizza and which on will not.  The competition contains a dataset with 5671 textual requests for pizza from the Reddit community Random Acts of Pizza together with their outcome (successful/unsuccessful) and meta-data. This data was collected and graciously shared by Althoff et al (http://www.timalthoff.com/). \n",
    "\n",
    "**Reference Paper:**\n",
    "Tim Althoff, Cristian Danescu-Niculescu-Mizil, Dan Jurafsky. How to Ask for a Favor: A Case Study on the Success of Altruistic Requests, Proceedings of ICWSM, 2014. (http://cs.stanford.edu/~althoff/raop-dataset/altruistic_requests_icwsm.pdf)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approach \n",
    "\n",
    "\n",
    "**Step 1:  Exploratory Data Analysis **\n",
    "\n",
    "**Step 2:  Create a Baseline Model **\n",
    "\n",
    "**Step 3:  Feature Engineering **\n",
    "\n",
    "- Preprocessing data \n",
    "    - data cleansing \n",
    "    - data transformation\n",
    "\n",
    "- Use other meta-data from the data set, such as,\n",
    "    - request_text_edit_aware\n",
    "    - request_title\n",
    "    - requester_account_age_in_days_at_request\n",
    "    - requester_days_since_first_post_on_raop_at_request\n",
    "    - requester_number_of_comments_at_request\n",
    "    - requester_number_of_comments_in_raop_at_request\n",
    "    - requester_number_of_posts_at_request\n",
    "    - requester_number_of_posts_on_raop_at_request\n",
    "    - requester_number_of_subreddits_at_request\n",
    "    - requester_subreddits_at_request\n",
    "    - requester_upvotes_minus_downvotes_at_request\n",
    "    - requester_upvotes_plus_downvotes_at_request\n",
    "    - requester_username\n",
    "    - unix_timestamp_of_request\n",
    "    - unix_timestamp_of_request_utc\n",
    "    - other features includes:\n",
    "        - number of requests made by the same user\n",
    "        - number of requests fulfilled or % of requests fulfilled, etc\n",
    "    \n",
    "- Generate new features from the data set such as, \n",
    "    - Politeness, \n",
    "    - Evidentiality, \n",
    "    - Reciprocity, \n",
    "    - Sentiment, \n",
    "    - Length, etc\n",
    "\n",
    "**Step 4:  Algorithm / Model Selection **\n",
    "\n",
    "- Generative Models \n",
    "    - Naive Bayes \n",
    "- Discriminative Models\n",
    "    - Logistic Regression  \n",
    "- Neural Network \n",
    "\n",
    "\n",
    "**Step 5:  Error Analysis & Optimization ** \n",
    "\n",
    "\n",
    "**Step 6:  Final Model ** \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "# SK-learn libraries for model selection \n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# json libraries to parse json file\n",
    "import json\n",
    "from pandas.io.json import json_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read json file\n",
    "train_json = json.load(open('train.json'))\n",
    "\n",
    "# normalize data and put in a dataframe\n",
    "train_json_df = json_normalize(train_json)\n",
    "\n",
    "# read json file\n",
    "test_json = json.load(open('test.json'))\n",
    "\n",
    "# normalize data and put in a dataframe\n",
    "test_json_df = json_normalize(test_json)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training data shape: (3232,)\n",
      "dev data shape: (808,)\n",
      "test data shape: (1631,)\n"
     ]
    }
   ],
   "source": [
    "# for the baseline, we just use the \"request_text_edit_aware\" as input features \n",
    "# but we can explore other metadata (such as \"request_title\", \n",
    "# \"number_of_downvotes_of_request_at_retrieval\", \"number_of_upvotes_of_request_at_retrieval\", etc) \n",
    "# to add to the input features \n",
    "train_data = train_json_df.request_text_edit_aware.as_matrix()\n",
    "\n",
    "# convert the requester_received_pizza field to 0 and 1\n",
    "# 0 means the user doesn't receive pizza & 1 means the user receives pizza\n",
    "train_labels = train_json_df.requester_received_pizza.astype(int).as_matrix()\n",
    "\n",
    "# split the training data into training data and dev data \n",
    "train_data, dev_data, train_labels, dev_labels = \\\n",
    "            train_test_split(train_data, train_labels, test_size=0.2, random_state=42)\n",
    "    \n",
    "    \n",
    "# apply same logic as train_data to test_data\n",
    "test_data = test_json_df.request_text_edit_aware.as_matrix()\n",
    "\n",
    "print('training data shape:', train_data.shape)\n",
    "print('dev data shape:', dev_data.shape)\n",
    "print('test data shape:', test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1:  Exploratory Data Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----------------------------------------------\n",
      "This message receives pizza : Sample 1\n",
      "-----------------------------------------------\n",
      "My power was out for about 3 hours earlier this afternoon. I keep trying to watch DVD's (Twister...I mean when in Rome, right?) but as soon as I get halfway in the power either flickers on and off or stays off for an extended period of time. I don't feel up to going out for food either since I've been sick for about 3 days now and Hurricane Irene is being a bitch...\n",
      "\n",
      "Thank you all!\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message receives pizza : Sample 2\n",
      "-----------------------------------------------\n",
      "I'm lucky that internet comes part and parcel with my rent. I work retail grocery and summer hours are murder on the wallet. I have to hustle managers just to get a good 20-25 hours a week, when I used to push the part time hour limit. \n",
      "\n",
      "I hate begging, but my stomach is scoffing at me and calling me a proud asshole. So here I am :). Just one is all I ask.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message receives pizza : Sample 3\n",
      "-----------------------------------------------\n",
      "Hey RAoP\n",
      "\n",
      "This is a throwaway account but I'd be happy to PM you from my real account as verification. I've given before and never received.\n",
      "\n",
      "First up I'd like to say that pizza is NOT necessary and we won't starve without it. Not even a bit. We've got some leftovers in the freezer and a bunch of odds and ends in the cupboards and even a bunch of friends who'd take us out to dinner or have us over if we asked (but we'd feel bad asking because we're old enough to be meant to be beyond this!). So, absolutely no worries if no-one can give. \n",
      "\n",
      "I'm asking because a bunch of unexpected grown up expenses just ambushed us. My boyfriend's grandfather died unexpectedly and we wanted to go to the funeral - but it was 5 hours away and we didn't have a car. So we bought a cheap car and made it to the funeral, but it turns out that car ownership is super expensive. Rego is nearly $1000! Add insurance, NRMA membership (needed cos we weren't sure whether our little bomb of a car would make the drive and we didnt want to be stranded in the australian outback forever), random fees for vehicle inspections and more random fees just for existing add up to be the value of the car again! What. The. Hell. (yes, I *have* lived a sheltered life, thank you for asking.)\n",
      "\n",
      "Add that to the billion and one other things we're saving up for/need to pay (rent, bills, house deposit, wedding, honeymoon maybe, helping our families) and it's come as a bit of a shock to our financial system :P\n",
      "We literally have $0.67 in the bank and a bit of change in cash until pay day. This is an odd and disconcerting feeling. \n",
      "\n",
      "What would pizza mean to us? Laughter and joy. The pleasure of knowing that there are good people who care about strangers. A memory to carry with us both when things are hard and when things are good and we can give again. A small easing of financial stress for the next few days. \n",
      "\n",
      "I might also pull the request later because like I said - it's most definitely not a do or die type situation. And anyway, my credit card's taken such a pounding this week, what harm is pizza going to do? :P\n",
      "\n",
      "But thanks for reading anyway, RAoP!\n",
      "\n",
      "Also, please and thank you ;)\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message receives pizza : Sample 4\n",
      "-----------------------------------------------\n",
      "I'm in Covington.  If anyone would give the gift of pizza, I'd be most most appreciative.  I'm a broke writer who only had ramen in his house.  Thanks!\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message receives pizza : Sample 5\n",
      "-----------------------------------------------\n",
      "I could really use a pizza right now.  It's my friend and I, and we have nothing to eat / no money.. and his car is in the shop.  So if one of you fine gentlemen , or fine ladies, could give us delicious, hot, circular-shaped heaven.. We would be most grateful.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message doesn't receive pizza : Sample 1\n",
      "-----------------------------------------------\n",
      "Posting from my phone (contract expires next Wednesday) as we have no wifi. Girlfriend and I met on the Internet, have been in a long-distance relationship (with monthly visits) for ten months. Just moved into a new apartment with her last week. I'm the happiest I've been in a long time, but we are pretty tight on money. I'm job-hunting, she works at a minimum wage fast food restaurant (she brings food back from her job, which is how we eat right now). A pizza or two would be nice if anyone has a few extra bucks lying around. We can handle the delivery guy's tip. Thanks. \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message doesn't receive pizza : Sample 2\n",
      "-----------------------------------------------\n",
      "Biochemistry is a hell of a major. \n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message doesn't receive pizza : Sample 3\n",
      "-----------------------------------------------\n",
      "So I made this throwaway because I just feel bad about having to post here, but it's a last resort.  I've been unemployed for a few months and my cash is just winding low.  I'm in the midst of classes that have been taking up my time and preventing me from finding a new job and I'm starting to really stress out about having to pay rent in ~10 days.  I'm not expecting anything, but I figured I'd try for a pizza.  I have a verification code.\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message doesn't receive pizza : Sample 4\n",
      "-----------------------------------------------\n",
      "I'm a full time student that also works full time, which means I never get time off! I'm enjoying the first day off I've had in over 3 months, but I have no food in the fridge and I don't get paid til wed! I'd be so grateful for a pizza right now &lt;3&lt;3\n",
      "\n",
      "\n",
      "-----------------------------------------------\n",
      "This message doesn't receive pizza : Sample 5\n",
      "-----------------------------------------------\n",
      "Hi guys, never done this before so I don't know if it will work or not but worth a shot is it not? Basically the situation is as follows.. I am in Wellington, New Zealand. I am hungover because last night I was out in town drinking and watching the warriors lose to manly in the NRL grand final :( used up most of my spare money taxing home and now I am looking at a fairly empty fridge/pantry.. My car is 30 mins walk away and it is PISSING down with rain which I don't really wanna brave to go to the super market.\n",
      "\n",
      "Pretty much wondering if a kickass random stranger would hook me up with a pizza to cure my hangover and cheer me up after yesterdays loss. Will be sure to pay it on in the future to another needy individual.\n",
      "\n",
      "Thankyou THR - you are the greatest!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "num_examples=5\n",
    "    \n",
    "# for each label, display a number of examples \n",
    "for i in range(2):\n",
    "\n",
    "    # find the indexes of the corresponding label \n",
    "    index = np.where(train_labels == i)\n",
    "\n",
    "    for j in range(num_examples):\n",
    "\n",
    "        # print the training data for that label\n",
    "        if i == 0:\n",
    "            title = \"This message receives pizza\"\n",
    "        else:\n",
    "            title = \"This message doesn't receive pizza\"\n",
    "        print(\"-----------------------------------------------\" )\n",
    "        print(\"{} : Sample {}\".format(title, j+1))\n",
    "        print(\"-----------------------------------------------\")\n",
    "        print(train_data[index[0][j]])\n",
    "        print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Create a Baseline Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.81727272727272726}\n",
      "f1 score using TfidfVectorizer & MultinomialNB = 0.7388613861386139\n"
     ]
    }
   ],
   "source": [
    "# use standard TfidfVectorizer to transform the training data and dev data \n",
    "vectorizer = TfidfVectorizer()\n",
    "train_bag_of_words = vectorizer.fit_transform(train_data)\n",
    "dev_bag_of_words = vectorizer.transform(dev_data)\n",
    "\n",
    "# create MultinomialNB\n",
    "nb = MultinomialNB()\n",
    "    \n",
    "# test the best value for alpha\n",
    "parameters = {'alpha': np.linspace(0.01, 10, 100)}\n",
    "\n",
    "# create GridSearchCV to find the best alpha\n",
    "clf = GridSearchCV(nb, parameters)\n",
    "    \n",
    "# train the MultinomialNB\n",
    "clf.fit(train_bag_of_words, train_labels)\n",
    "\n",
    "pred_dev_labels = clf.predict(dev_bag_of_words)\n",
    "\n",
    "print(clf.best_params_)\n",
    "print(\"f1 score using TfidfVectorizer & MultinomialNB = {}\".format(metrics.f1_score(dev_labels, pred_dev_labels, average='micro')))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:anaconda3]",
   "language": "python",
   "name": "conda-env-anaconda3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
